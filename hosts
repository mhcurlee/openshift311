

[masters]

ip-172-30-0-158.ec2.internal
ip-172-30-0-5.ec2.internal
ip-172-30-0-251.ec2.internal

[etcd]

ip-172-30-0-158.ec2.internal
ip-172-30-0-5.ec2.internal
ip-172-30-0-251.ec2.internal

[nodes]

ip-172-30-0-158.ec2.internal openshift_node_group_name="node-config-master"
ip-172-30-0-5.ec2.internal openshift_node_group_name="node-config-master"
ip-172-30-0-251.ec2.internal openshift_node_group_name="node-config-master"

ip-172-30-0-89.ec2.internal openshift_node_group_name="node-config-infra"
ip-172-30-0-168.ec2.internal openshift_node_group_name="node-config-infra"
ip-172-30-0-123.ec2.internal openshift_node_group_name="node-config-infra"

ip-172-30-0-69.ec2.internal openshift_node_group_name="node-config-compute"
ip-172-30-0-96.ec2.internal openshift_node_group_name="node-config-compute"
ip-172-30-0-117.ec2.internal openshift_node_group_name="node-config-compute"



[OSEv3:children]
masters
nodes
etcd

[OSEv3:vars]

openshift_deployment_type=origin
#openshift_release="3.11"
#openshift_image_tag=v3.11.0
#openshift_pkg_version=-3.11.0
openshift_master_default_subdomain=apps.gocurlee.com
openshift_master_cluster_hostname=master.gocurlee.com
openshift_master_cluster_public_hostname=master.gocurlee.com
openshift_master_cluster_method=native
openshift_master_api_port=443
openshift_master_console_port=443


os_sdn_network_plugin_name='redhat/openshift-ovs-multitenant'
osm_cluster_network_cidr=10.128.0.0/14
openshift_portal_net=10.254.0.0/16
osm_host_subnet_length=9





###############################################################################
# Additional configuration variables follow                                   #
###############################################################################

# Debug level for all OpenShift components (Defaults to 2)
debug_level=2




# Manage openshift example imagestreams and templates during install and upgrade
#openshift_install_examples=true



# Configure imagePolicyConfig in the master config
#openshift_master_image_policy_allowed_registries_for_import=["docker.io", "*.docker.io", "*.redhat.com", "gcr.io", "quay.io", "registry.centos.org", "registry.redhat.io", "*.amazonaws.com"]




# Cluster Image Source (registry) configuration
#oreg_auth_user=some_user
#oreg_auth_password='my-pass'


# htpasswd auth
#openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]
# Defining htpasswd users
#openshift_master_htpasswd_users={'user1': '<pre-hashed password>', 'user2': '<pre-hashed password>'}
# or
#openshift_master_htpasswd_file=<path to local pre-generated htpasswd file>

# Allow all auth
#openshift_master_identity_providers=[{'name': 'allow_all', 'login': 'true', 'challenge': 'true', 'kind': 'AllowAllPasswordIdentityProvider'}]



# External NFS Host

openshift_hosted_registry_storage_kind=nfs
openshift_hosted_registry_storage_access_modes=['ReadWriteMany']
openshift_hosted_registry_storage_host=ip-172-30-0-190.ec2.internal
openshift_hosted_registry_storage_nfs_directory=/pub
openshift_hosted_registry_storage_volume_name=registry
openshift_hosted_registry_storage_volume_size=10Gi





# Metrics deployment
# See: https://docs.openshift.com/container-platform/latest/install_config/cluster_metrics.html
#
# By default metrics are not automatically deployed, set this to enable them
#openshift_metrics_install_metrics=true
#
# metrics-server deployment
# By default, metrics-server is not automatically deployed, unless metrics is also
# deployed.  Deploying metrics-server is necessary to use the HorizontalPodAutoscaler.
# Set this to enable it.
#openshift_metrics_server_install=true
#
# Storage Options
# If openshift_metrics_storage_kind is unset then metrics will be stored
# in an EmptyDir volume and will be deleted when the cassandra pod terminates.
# Storage options A & B currently support only one cassandra pod which is
# generally enough for up to 1000 pods. Additional volumes can be created
# manually after the fact and metrics scaled per the docs.
#
# Option A - NFS Host Group
# An NFS volume will be created with path "nfs_directory/volume_name"
# on the host within the [nfs] host group.  For example, the volume
# path using these options would be "/exports/metrics".  "exports" is
# is the name of the export served by the nfs server.  "metrics" is
# the name of a directory inside of "/exports".
#openshift_metrics_storage_kind=nfs
#openshift_metrics_storage_access_modes=['ReadWriteOnce']
#openshift_metrics_storage_nfs_directory=/exports
#openshift_metrics_storage_nfs_options='*(rw,root_squash)'
#openshift_metrics_storage_volume_name=metrics
#openshift_metrics_storage_volume_size=10Gi
#openshift_metrics_storage_labels={'storage': 'metrics'}
#
# Option B - External NFS Host
# NFS volume must already exist with path "nfs_directory/_volume_name" on
# the storage_host. For example, the remote volume path using these
# options would be "nfs.example.com:/exports/metrics".  "exports" is
# is the name of the export served by the nfs server.  "metrics" is
# the name of a directory inside of "/exports".
#openshift_metrics_storage_kind=nfs
#openshift_metrics_storage_access_modes=['ReadWriteOnce']
#openshift_metrics_storage_host=nfs.example.com
#openshift_metrics_storage_nfs_directory=/exports
#openshift_metrics_storage_volume_name=metrics
#openshift_metrics_storage_volume_size=10Gi
#openshift_metrics_storage_labels={'storage': 'metrics'}
#
# Option C - Dynamic -- If openshift supports dynamic volume provisioning for
# your cloud platform use this.
#openshift_metrics_storage_kind=dynamic
#
# Other Metrics Options -- Common items you may wish to reconfigure, for the complete
# list of options please see roles/openshift_metrics/README.md
#
# Override metricsPublicURL in the master config for cluster metrics
# Defaults to https://hawkular-metrics.{{openshift_master_default_subdomain}}/hawkular/metrics
# Currently, you may only alter the hostname portion of the url, alterting the
# `/hawkular/metrics` path will break installation of metrics.
#openshift_metrics_hawkular_hostname=hawkular-metrics.example.com
# Configure the metrics component images # Note, these will be modified by oreg_url by default
#openshift_metrics_cassandra_image="docker.io/openshift/origin-metrics-cassandra:{{ openshift_image_tag }}"
#openshift_metrics_hawkular_agent_image="docker.io/openshift/origin-metrics-hawkular-openshift-agent:{{ openshift_image_tag }}"
#openshift_metrics_hawkular_metrics_image="docker.io/openshift/origin-metrics-hawkular-metrics:{{ openshift_image_tag }}"
#openshift_metrics_schema_installer_image="docker.io/openshift/origin-metrics-schema-installer:{{ openshift_image_tag }}"
#openshift_metrics_heapster_image="docker.io/openshift/origin-metrics-heapster:{{ openshift_image_tag }}"
# when openshift_deployment_type=='openshift-enterprise'
#openshift_metrics_cassandra_image="registry.redhat.io/openshift3/metrics-cassandra:{{ openshift_image_tag }}"
#openshift_metrics_hawkular_agent_image="registry.redhat.io/openshift3/metrics-hawkular-openshift-agent:{{ openshift_image_tag }}"
#openshift_metrics_hawkular_metrics_image="registry.redhat.io/openshift3/metrics-hawkular-metrics:{{ openshift_image_tag }}"
#openshift_metrics_schema_installer_image="registry.redhat.io/openshift3/metrics-schema-installer:{{ openshift_image_tag }}"
#openshift_metrics_heapster_image="registry.redhat.io/openshift3/metrics-heapster:{{ openshift_image_tag }}"
#
# StorageClass
# openshift_storageclass_name=gp2
# openshift_storageclass_parameters={'type': 'gp2', 'encrypted': 'false'}
# openshift_storageclass_mount_options=['dir_mode=0777', 'file_mode=0777']
# openshift_storageclass_reclaim_policy="Delete"
#
# PersistentLocalStorage
# If Persistent Local Storage is wanted, this boolean can be defined to True.
# This will create all necessary configuration to use persistent storage on nodes.
#openshift_persistentlocalstorage_enabled=False
#openshift_persistentlocalstorage_classes=[]
#openshift_persistentlocalstorage_path=/mnt/local-storage
#openshift_persistentlocalstorage_provisionner_image=quay.io/external_storage/local-volume-provisioner:v1.0.1

# Cluster monitoring
#
# Cluster monitoring is enabled by default, disable it by setting
# openshift_cluster_monitoring_operator_install=false
#
# Cluster monitoring configuration variables allow setting the amount of
# storage and storageclass requested through PersistentVolumeClaims.
#
# openshift_cluster_monitoring_operator_prometheus_storage_capacity="50Gi"
# openshift_cluster_monitoring_operator_alertmanager_storage_capacity="2Gi"
#
# openshift_cluster_monitoring_operator_prometheus_storage_class_name=""
# openshift_cluster_monitoring_operator_alertmanager_storage_class_name=""

# Update the time to wait for CRD to be creating by setting
# openshift_cluster_monitoring_operator_crd_retries=30
# openshift_cluster_monitoring_operator_crd_delay=30


# Logging deployment
#
# Currently logging deployment is disabled by default, enable it by setting this
#openshift_logging_install_logging=true
#
# Logging storage config
# Option A - NFS Host Group
# An NFS volume will be created with path "nfs_directory/volume_name"
# on the host within the [nfs] host group.  For example, the volume
# path using these options would be "/exports/logging".  "exports" is
# is the name of the export served by the nfs server.  "logging" is
# the name of a directory inside of "/exports".
#openshift_logging_storage_kind=nfs
#openshift_logging_storage_access_modes=['ReadWriteOnce']
#openshift_logging_storage_nfs_directory=/exports
#openshift_logging_storage_nfs_options='*(rw,root_squash)'
#openshift_logging_storage_volume_name=logging
#openshift_logging_storage_volume_size=10Gi
#openshift_logging_storage_labels={'storage': 'logging'}
#
# Option B - External NFS Host
# NFS volume must already exist with path "nfs_directory/_volume_name" on
# the storage_host. For example, the remote volume path using these
# options would be "nfs.example.com:/exports/logging".  "exports" is
# is the name of the export served by the nfs server.  "logging" is
# the name of a directory inside of "/exports".
#openshift_logging_storage_kind=nfs
#openshift_logging_storage_access_modes=['ReadWriteOnce']
#openshift_logging_storage_host=nfs.example.com
#openshift_logging_storage_nfs_directory=/exports
#openshift_logging_storage_volume_name=logging
#openshift_logging_storage_volume_size=10Gi
#openshift_logging_storage_labels={'storage': 'logging'}
#
# Option C - Dynamic -- If openshift supports dynamic volume provisioning for
# your cloud platform use this.
#openshift_logging_storage_kind=dynamic
#
# Option D - none -- Logging will use emptydir volumes which are destroyed when
# pods are deleted
#
# Other Logging Options -- Common items you may wish to reconfigure, for the complete
# list of options please see roles/openshift_logging/README.md
#
# Configure loggingPublicURL in the master config for aggregate logging, defaults
# to kibana.{{ openshift_master_default_subdomain }}
#openshift_logging_kibana_hostname=logging.apps.example.com
# Configure the number of elastic search nodes, unless you're using dynamic provisioning
# this value must be 1
#openshift_logging_es_cluster_size=1











# Enable service catalog
#openshift_enable_service_catalog=true

# Enable template service broker (requires service catalog to be enabled, above)
#template_service_broker_install=true

# Specify an openshift_service_catalog image
# (defaults for origin and openshift-enterprise, repsectively)
#openshift_service_catalog_image="docker.io/openshift/origin-service-catalog:{{ openshift_image_tag }}""
#openshift_service_catalog_image="registry.redhat.io/openshift3/ose-service-catalog:{{ openshift_image_tag }}"

# Configure one of more namespaces whose templates will be served by the TSB
#openshift_template_service_broker_namespaces=['openshift']

# masterConfig.volumeConfig.dynamicProvisioningEnabled, configurable as of 1.2/3.2, enabled by default
#openshift_master_dynamic_provisioning_enabled=True

# Admission plugin config
#openshift_master_admission_plugin_config={"ProjectRequestLimit":{"configuration":{"apiVersion":"v1","kind":"ProjectRequestLimitConfig","limits":[{"selector":{"admin":"true"}},{"maxProjects":"1"}]}},"PodNodeConstraints":{"configuration":{"apiVersion":"v1","kind":"PodNodeConstraintsConfig"}}}

# Configure usage of openshift_clock role.
#openshift_clock_enabled=true


